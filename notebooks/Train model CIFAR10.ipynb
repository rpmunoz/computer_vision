{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GPUS = 1\n",
    "BS_PER_GPU = 64\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "HEIGHT = 32\n",
    "WIDTH = 32\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "NUM_TRAIN_SAMPLES = 50000\n",
    "\n",
    "BASE_LEARNING_RATE = 0.1\n",
    "LR_SCHEDULE = [(0.1, 30), (0.01, 45)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsDir = 'models'\n",
    "resultsDir = 'results'\n",
    "logsDir = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, y):\n",
    "  x = tf.image.per_image_standardization(x)\n",
    "  return x, y\n",
    "\n",
    "\n",
    "def augmentation(x, y):\n",
    "    x = tf.image.resize_with_crop_or_pad(\n",
    "        x, HEIGHT + 8, WIDTH + 8)\n",
    "    x = tf.image.random_crop(x, [HEIGHT, WIDTH, NUM_CHANNELS])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x, y\t\n",
    "\n",
    "\n",
    "def schedule(epoch):\n",
    "  initial_learning_rate = BASE_LEARNING_RATE * BS_PER_GPU / 128\n",
    "  learning_rate = initial_learning_rate\n",
    "  for mult, start_epoch in LR_SCHEDULE:\n",
    "    if epoch >= start_epoch:\n",
    "      learning_rate = initial_learning_rate * mult\n",
    "    else:\n",
    "      break\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "tf.random.set_seed(22)\n",
    "train_dataset = train_dataset.map(augmentation).map(normalize).shuffle(NUM_TRAIN_SAMPLES).batch(BS_PER_GPU * NUM_GPUS, drop_remainder=True)\n",
    "test_dataset = test_dataset.map(normalize).batch(BS_PER_GPU * NUM_GPUS, drop_remainder=True)\n",
    "\n",
    "\n",
    "input_shape = (HEIGHT, WIDTH, NUM_CHANNELS)\n",
    "img_input = tf.keras.layers.Input(shape=input_shape)\n",
    "opt = keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "\n",
    "if NUM_GPUS == 1:\n",
    "    model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)\n",
    "    model.compile(\n",
    "              optimizer=opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "else:\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "      model = resnet.resnet56(img_input=img_input, classes=NUM_CLASSES)\n",
    "      model.compile(\n",
    "                optimizer=opt,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['sparse_categorical_accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/781 [..............................] - ETA: 0s - loss: 5.6268 - sparse_categorical_accuracy: 0.0312WARNING:tensorflow:From /data/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/781 [..............................] - ETA: 57s - loss: 4.6908 - sparse_categorical_accuracy: 0.1016WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0313s vs `on_train_batch_end` time: 0.1143s). Check your callbacks.\n",
      "781/781 [==============================] - 29s 37ms/step - loss: 2.7804 - sparse_categorical_accuracy: 0.2675 - val_loss: 2.9466 - val_sparse_categorical_accuracy: 0.2429\n",
      "Epoch 2/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 2.1365 - sparse_categorical_accuracy: 0.4437 - val_loss: 3.1172 - val_sparse_categorical_accuracy: 0.3055\n",
      "Epoch 3/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.7540 - sparse_categorical_accuracy: 0.5506 - val_loss: 2.7139 - val_sparse_categorical_accuracy: 0.3427\n",
      "Epoch 4/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.4960 - sparse_categorical_accuracy: 0.6211 - val_loss: 2.3517 - val_sparse_categorical_accuracy: 0.4250\n",
      "Epoch 5/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.3213 - sparse_categorical_accuracy: 0.6726 - val_loss: 2.1741 - val_sparse_categorical_accuracy: 0.4978\n",
      "Epoch 6/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.1872 - sparse_categorical_accuracy: 0.7126 - val_loss: 1.8527 - val_sparse_categorical_accuracy: 0.5373\n",
      "Epoch 7/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.1061 - sparse_categorical_accuracy: 0.7342 - val_loss: 2.2126 - val_sparse_categorical_accuracy: 0.4704\n",
      "Epoch 8/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 1.0391 - sparse_categorical_accuracy: 0.7520 - val_loss: 1.5691 - val_sparse_categorical_accuracy: 0.5998\n",
      "Epoch 9/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.9939 - sparse_categorical_accuracy: 0.7706 - val_loss: 1.5038 - val_sparse_categorical_accuracy: 0.6390\n",
      "Epoch 10/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.9605 - sparse_categorical_accuracy: 0.7816 - val_loss: 1.5094 - val_sparse_categorical_accuracy: 0.6458\n",
      "Epoch 11/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.9290 - sparse_categorical_accuracy: 0.7940 - val_loss: 1.8666 - val_sparse_categorical_accuracy: 0.5510\n",
      "Epoch 12/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.9215 - sparse_categorical_accuracy: 0.7985 - val_loss: 1.5263 - val_sparse_categorical_accuracy: 0.6366\n",
      "Epoch 13/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8971 - sparse_categorical_accuracy: 0.8133 - val_loss: 1.3993 - val_sparse_categorical_accuracy: 0.6582\n",
      "Epoch 14/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8891 - sparse_categorical_accuracy: 0.8172 - val_loss: 1.3520 - val_sparse_categorical_accuracy: 0.6862\n",
      "Epoch 15/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8828 - sparse_categorical_accuracy: 0.8255 - val_loss: 1.8345 - val_sparse_categorical_accuracy: 0.6292\n",
      "Epoch 16/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8739 - sparse_categorical_accuracy: 0.8320 - val_loss: 1.5102 - val_sparse_categorical_accuracy: 0.6712\n",
      "Epoch 17/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8691 - sparse_categorical_accuracy: 0.8378 - val_loss: 1.5810 - val_sparse_categorical_accuracy: 0.6523\n",
      "Epoch 18/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8724 - sparse_categorical_accuracy: 0.8422 - val_loss: 1.5163 - val_sparse_categorical_accuracy: 0.6768\n",
      "Epoch 19/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8676 - sparse_categorical_accuracy: 0.8470 - val_loss: 1.7068 - val_sparse_categorical_accuracy: 0.6472\n",
      "Epoch 20/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8691 - sparse_categorical_accuracy: 0.8492 - val_loss: 1.7564 - val_sparse_categorical_accuracy: 0.5917\n",
      "Epoch 21/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8694 - sparse_categorical_accuracy: 0.8540 - val_loss: 2.0371 - val_sparse_categorical_accuracy: 0.5968\n",
      "Epoch 22/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8636 - sparse_categorical_accuracy: 0.8591 - val_loss: 1.6214 - val_sparse_categorical_accuracy: 0.6707\n",
      "Epoch 23/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8745 - sparse_categorical_accuracy: 0.8601 - val_loss: 1.5375 - val_sparse_categorical_accuracy: 0.6779\n",
      "Epoch 24/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8763 - sparse_categorical_accuracy: 0.8634 - val_loss: 1.9847 - val_sparse_categorical_accuracy: 0.6233\n",
      "Epoch 25/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8731 - sparse_categorical_accuracy: 0.8658 - val_loss: 2.2055 - val_sparse_categorical_accuracy: 0.6126\n",
      "Epoch 26/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8771 - sparse_categorical_accuracy: 0.8687 - val_loss: 2.0060 - val_sparse_categorical_accuracy: 0.6168\n",
      "Epoch 27/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8763 - sparse_categorical_accuracy: 0.8705 - val_loss: 1.5677 - val_sparse_categorical_accuracy: 0.6815\n",
      "Epoch 28/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8752 - sparse_categorical_accuracy: 0.8721 - val_loss: 1.8648 - val_sparse_categorical_accuracy: 0.6196\n",
      "Epoch 29/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8827 - sparse_categorical_accuracy: 0.8747 - val_loss: 2.2454 - val_sparse_categorical_accuracy: 0.5823\n",
      "Epoch 30/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.8847 - sparse_categorical_accuracy: 0.8762 - val_loss: 1.8706 - val_sparse_categorical_accuracy: 0.6575\n",
      "Epoch 31/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.5135 - sparse_categorical_accuracy: 0.9965 - val_loss: 1.3278 - val_sparse_categorical_accuracy: 0.7878\n",
      "Epoch 35/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.4915 - sparse_categorical_accuracy: 0.9982 - val_loss: 1.3545 - val_sparse_categorical_accuracy: 0.7878\n",
      "Epoch 36/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.4729 - sparse_categorical_accuracy: 0.9991 - val_loss: 1.3660 - val_sparse_categorical_accuracy: 0.7873\n",
      "Epoch 37/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.4560 - sparse_categorical_accuracy: 0.9996 - val_loss: 1.3672 - val_sparse_categorical_accuracy: 0.7902\n",
      "Epoch 38/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.4410 - sparse_categorical_accuracy: 0.9997 - val_loss: 1.3758 - val_sparse_categorical_accuracy: 0.7870\n",
      "Epoch 39/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.4266 - sparse_categorical_accuracy: 0.9998 - val_loss: 1.3726 - val_sparse_categorical_accuracy: 0.7878\n",
      "Epoch 40/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.4130 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.3691 - val_sparse_categorical_accuracy: 0.7858\n",
      "Epoch 41/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.4001 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.3661 - val_sparse_categorical_accuracy: 0.7866\n",
      "Epoch 42/50\n",
      "151/781 [====>.........................] - ETA: 20s - loss: 0.3926 - sparse_categorical_accuracy: 0.9999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 27s 34ms/step - loss: 0.3456 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3467 - val_sparse_categorical_accuracy: 0.7845\n",
      "Epoch 48/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.3447 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3454 - val_sparse_categorical_accuracy: 0.7842\n",
      "Epoch 49/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.3435 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3458 - val_sparse_categorical_accuracy: 0.7847\n",
      "Epoch 50/50\n",
      "781/781 [==============================] - 27s 34ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.9999 - val_loss: 1.3450 - val_sparse_categorical_accuracy: 0.7836\n",
      "\n",
      "Total time for model training: 26.860927093029023 minutes\n"
     ]
    }
   ],
   "source": [
    "logs = os.path.join(logsDir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(logs + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "  log_dir=logs,\n",
    "#  update_freq='epoch', #'batch'\n",
    "  histogram_freq=1)\n",
    "\n",
    "lr_schedule_callback = keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          epochs=NUM_EPOCHS,\n",
    "          validation_data=test_dataset,\n",
    "          validation_freq=1,\n",
    "          callbacks=[tensorboard_callback, lr_schedule_callback])\n",
    "\n",
    "endTime = time.time()\n",
    "\n",
    "elapsedTime = (endTime - startTime)/60.\n",
    "print(\"\\nTotal time for model training: {} minutes\".format(elapsedTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.evaluate(test_dataset)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "new_model = keras.models.load_model('model.h5')\n",
    " \n",
    "new_model.evaluate(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
